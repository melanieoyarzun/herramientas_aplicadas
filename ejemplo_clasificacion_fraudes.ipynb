{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584243e3",
   "metadata": {},
   "source": [
    "# Herramienta aplicada unidad 4\n",
    "## Ejemplo de clasificación de fraudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517f89",
   "metadata": {},
   "source": [
    "\n",
    "Una aplicación común de Machine Learning es la detección de fraudes en transacciones financieras. \n",
    "En este notebook, se presenta un ejemplo de cómo implementar una detección de fraudes utilizando algoritmos de Machine Learning en Python.\n",
    "\n",
    "En esta oportunidad, usaremos el lenguaje Python y algunas de sus librerías más utilizadas. La idea es que conozcas \n",
    "cómo se implementan estos modelos, aunque en este caso se usarán datos ficticios y simulados que no representan \n",
    "la complejidad de un análisis real en esta área.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893208a6",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Supongamos que tenemos un conjunto de datos con información sobre transacciones bancarias. Cada observación represnta una transacción y las variables incluidas son:\n",
    "- Monto de la transacción (en dólares)\n",
    "- Hora de la transacción (en formato de 24 hrs)\n",
    "- Tipo de transaccion (retiro, depósito, transferencia)\n",
    "- Ubicación de la transacción (local, nacional, internacional)\n",
    "- Tarjeta de crédito utilizada (número de tarjeta)\n",
    "\n",
    "Para simular los datos, podemos generar un conjunto de observaciones aleatorias con distribuciones específicas para cada variable. En este caso, asumiremos que hay un 5% de transacciones fraudulentas en el conjunto de datos.\n",
    "\n",
    "En este ejemplo, crearé un conjunto de datos de transacciones financieras con 10,000 transacciones. Estableceré una proporción del % de transacciones fraudulentas, lo que significa que habrá 500 transacciones fraudulentas en el conjunto de datos. Además, crearé algunas características que podrían ser útiles para identificar transacciones fraudulentas, como un monto alto, una ubicación inusual, un\n",
    "horario inusual y un tipo de transacción inusual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fijar una semilla para la reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Número de transacciones\n",
    "n_transacciones = 10000\n",
    "\n",
    "# Crear un conjunto de datos con transacciones normales\n",
    "datos_normales = pd.DataFrame({\n",
    "    'monto': np.random.normal(loc=50, scale=10, size=n_transacciones),\n",
    "    'ubicacion': np.random.choice(['EEUU', 'México', 'Canadá'], size=n_transacciones),\n",
    "    'horario': np.random.choice(['día', 'noche'], size=n_transacciones),\n",
    "    'tipo': np.random.choice(['compra', 'retiro'], size=n_transacciones),\n",
    "    'clase': np.zeros(n_transacciones)\n",
    "})\n",
    "\n",
    "# Crear un conjunto de datos con transacciones fraudulentas\n",
    "datos_fraudulentos = pd.DataFrame({\n",
    "    'monto': np.random.normal(loc=100, scale=20, size=int(n_transacciones * 0.05)),\n",
    "    'ubicacion': np.random.choice(['Nigeria', 'Rusia', 'China'], size=int(n_transacciones * 0.05)),\n",
    "    'horario': np.random.choice(['día', 'noche'], size=int(n_transacciones * 0.05)),\n",
    "    'tipo': np.random.choice(['compra', 'retiro'], size=int(n_transacciones * 0.05)),\n",
    "    'clase': np.ones(int(n_transacciones * 0.05))\n",
    "})\n",
    "\n",
    "# Combinar los conjuntos de datos y mezclar\n",
    "datos = pd.concat([datos_normales, datos_fraudulentos]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Visualizar las primeras filas de los datos\n",
    "datos.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1f143",
   "metadata": {},
   "source": [
    "\n",
    "### Explicación de técnicas de modelado para la detección de fraude\n",
    "\n",
    "Con estos datos simulados, podemos aplicar diferentes técnicas de modelado para detectar patrones en las transacciones \n",
    "que puedan indicar la presencia de fraude.\n",
    "\n",
    "Existen varias técnicas de modelado que se pueden aplicar para detectar patrones de fraude en transacciones, algunas \n",
    "de las más comunes son:\n",
    "\n",
    "1. **Regresión logística**: Un modelo de regresión logística que predice la probabilidad de que una transacción sea \n",
    "fraudulenta o no, basado en una serie de variables explicativas.\n",
    "\n",
    "2. **Árboles de decisión**: Dividen los datos en diferentes subgrupos con características similares, ayudando a \n",
    "identificar patrones de fraude y clasificar transacciones.\n",
    "\n",
    "3. **Redes neuronales**: Modelos basados en el funcionamiento del cerebro humano que identifican patrones complejos \n",
    "en grandes conjuntos de datos.\n",
    "\n",
    "4. **Análisis de anomalías**: Detecta patrones inusuales o anómalos en los datos, útil para identificar transacciones sospechosas.\n",
    "\n",
    "5. **Clustering**: Agrupa transacciones con características similares, ayudando a detectar patrones de fraude en esos \n",
    "grupos.\n",
    "\n",
    "Para este ejemplo, utilizaremos las técnicas 1, 2 y 5 de manera sintética.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bf10f",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Codificar las variables categóricas usando la técnica de codificación one-hot\n",
    "datos_codificados = pd.get_dummies(datos, columns=['ubicacion', 'horario', 'tipo'])\n",
    "datos_codificados.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37ac36",
   "metadata": {},
   "source": [
    "### Implementación de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y prueba\n",
    "X = datos_codificados.drop('clase', axis=1)\n",
    "y = datos_codificados['clase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar un modelo de regresión logística\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño del modelo en el conjunto de prueba\n",
    "print(\"Matriz de confusión:\n",
    "\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Reporte de clasificación:\n",
    "\", classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373e639",
   "metadata": {},
   "source": [
    "### Predicción con nuevos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir nuevos datos simulados\n",
    "nuevos_datos = pd.DataFrame({\n",
    "    'monto': [80, 30, 120, 60, 60, 100],\n",
    "    'ubicacion': ['EEUU', 'Canadá', 'Rusia', 'México', 'China', 'Nigeria'],\n",
    "    'horario': ['día', 'noche', 'noche', 'día', 'noche', 'noche'],\n",
    "    'tipo': ['compra', 'retiro', 'compra', 'retiro', 'retiro', 'retiro']\n",
    "})\n",
    "\n",
    "# Preprocesar los nuevos datos\n",
    "nuevos_datos_procesados = pd.get_dummies(nuevos_datos, columns=['ubicacion', 'horario', 'tipo'])\n",
    "\n",
    "# Hacer predicciones sobre los nuevos datos\n",
    "predicciones = lr_model.predict(nuevos_datos_procesados)\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(\"Predicciones:\", predicciones)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb26c46",
   "metadata": {},
   "source": [
    "### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear modelo de árbol de decisión\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Entrenar el modelo en el conjunto de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Imprimir el informe de clasificación\n",
    "print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926c377",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ba955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reducir el conjunto de datos para hacer el clustering (sin la variable de clase)\n",
    "X_clustering = datos_codificados.drop('clase', axis=1)\n",
    "\n",
    "# Definir el modelo de K-Means con un número arbitrario de clusters\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X_clustering)\n",
    "\n",
    "# Agregar los clusters a los datos originales\n",
    "datos['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualizar la distribución de clases en cada cluster\n",
    "print(datos.groupby('cluster')['clase'].value_counts())\n",
    "\n",
    "# Visualización de los clusters (utilizando solo dos dimensiones para simplicidad)\n",
    "plt.scatter(datos['monto'], datos['cluster'], c=datos['clase'])\n",
    "plt.xlabel('Monto de la transacción')\n",
    "plt.ylabel('Cluster asignado')\n",
    "plt.title('Distribución de clusters')\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
